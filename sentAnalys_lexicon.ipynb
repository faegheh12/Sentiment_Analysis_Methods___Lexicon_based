{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Faegheh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Faegheh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Faegheh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Faegheh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from afinn import Afinn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Sentiment Analysis methodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AFINN(text):\n",
    "    afinn = Afinn()\n",
    "    return afinn.score(text)\n",
    "\n",
    "\n",
    "\n",
    "def SentiWordNet(pos_data):\n",
    "    sentiment = 0\n",
    "    tokens_count = 0\n",
    "    for word, pos in pos_data:\n",
    "        if not pos:\n",
    "            continue\n",
    "        lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
    "        if not lemma:\n",
    "            continue\n",
    "        \n",
    "        synsets = wordnet.synsets(lemma, pos=pos)\n",
    "        if not synsets:\n",
    "            continue\n",
    "        synset = synsets[0]\n",
    "        swn_synset = swn.senti_synset(synset.name())\n",
    "        sentiment += swn_synset.pos_score() - swn_synset.neg_score()\n",
    "        tokens_count += 1\n",
    "        \n",
    "    if not tokens_count:\n",
    "        return 0\n",
    "    if sentiment>0:\n",
    "        return \"Positive\", sentiment\n",
    "    if sentiment==0:\n",
    "        return \"Neutral\", sentiment\n",
    "    else:\n",
    "        return \"Negative\", sentiment\n",
    "\n",
    "\n",
    "\n",
    "def VADER(text):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    result = analyzer.polarity_scores(text)['compound']\n",
    "    if result >= 0.5:\n",
    "        return 'Positive', analyzer.polarity_scores(text)['pos']\n",
    "    elif result <= -0.5 :\n",
    "        return 'Negative', analyzer.polarity_scores(text)['neg']\n",
    "    else:\n",
    "        return 'Neutral', analyzer.polarity_scores(text)['neu']\n",
    "                                                         \n",
    "\n",
    "\n",
    "def Textblob(text):\n",
    "    Polarity = TextBlob(text).sentiment.polarity\n",
    "    if Polarity < 0:\n",
    "        res = 'Negative'\n",
    "    elif Polarity == 0:\n",
    "        res = 'Neutral'\n",
    "    else:\n",
    "        res = 'Positive'\n",
    "    return res, Polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function for calculate sentiment analysis score with above methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sentiment_Analysis_lex(dataset,text_name,methods):\n",
    "\n",
    "    # dataset: path of csv file\n",
    "    # text_name: name of texts column\n",
    "    # methods: list of sentiment analysis methods\n",
    "\n",
    "    # create dataframe and Data preprocessing steps\n",
    "     \n",
    "    my_data = pd.read_csv(dataset)\n",
    "\n",
    "    # Cleaning the text\n",
    "    def clean_text(text):\n",
    "        text = re.sub('[^A-Za-z]+', ' ', text) \n",
    "        return text\n",
    "    \n",
    "    # Tokenization, POS tagging, stopwords removal\n",
    "    def Tokenization_POS_stopwords(text):\n",
    "        # POS tagger dictionary\n",
    "        pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}\n",
    "        tags = pos_tag(word_tokenize(text))\n",
    "        newlist = []\n",
    "        for word, tag in tags:\n",
    "            if word.lower() not in set(stopwords.words('english')):\n",
    "                newlist.append(tuple([word, pos_dict.get(tag[0])]))\n",
    "        return newlist\n",
    "    \n",
    "    # Lemmatization\n",
    "    def lemmatiz(pos_data):\n",
    "        lemma_rew = \" \"\n",
    "        for word, pos in pos_data:\n",
    "            if not pos: \n",
    "                lemma = word\n",
    "                lemma_rew = lemma_rew + \" \" + lemma\n",
    "            else:  \n",
    "                lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
    "                lemma_rew = lemma_rew + \" \" + lemma\n",
    "        return lemma_rew\n",
    "\n",
    "    # create Required dataset\n",
    "    my_data['Cleaned_Doc'] = my_data[text_name].apply(clean_text)\n",
    "    my_data['POS_tagged'] = my_data['Cleaned_Doc'].apply(Tokenization_POS_stopwords)\n",
    "    my_data['Lemma'] = my_data['POS_tagged'].apply(lemmatiz)\n",
    "\n",
    "\n",
    "                    ####-------------------------------------------------####\n",
    "    if methods == 'all':\n",
    "        my_data['AFINN_Score'] = my_data['Cleaned_Doc'].apply(AFINN)\n",
    "        my_data[['SentiWordNet_polarity', 'SentiWordNet_Score']] = my_data['POS_tagged'].apply(lambda x: pd.Series(SentiWordNet(x)))\n",
    "        my_data[['Vader_polarity', 'vader_Score']] = my_data['Lemma'].apply(lambda x: pd.Series(VADER(x)))\n",
    "        my_data[['TextBlob_polarity', 'TextBlob_Score']] = my_data['Lemma'].apply(lambda x: pd.Series(Textblob(x)))\n",
    "    else:\n",
    "        for li in methods:\n",
    "            if li == 'AFINN':\n",
    "                my_data['AFINN_Score'] = my_data['Cleaned_Doc'].apply(AFINN)\n",
    "            if li == 'SentiWordNet':\n",
    "                my_data[['SentiWordNet_polarity', 'SentiWordNet_Score']] = my_data['POS_tagged'].apply(lambda x: pd.Series(SentiWordNet(x)))\n",
    "            if li == 'VADER':\n",
    "                my_data[['Vader_polarity', 'vader_Score']] = my_data['Lemma'].apply(lambda x: pd.Series(VADER(x)))\n",
    "            if li == 'TextBlob':\n",
    "                my_data[['TextBlob_polarity', 'TextBlob_Score']] = my_data['Lemma'].apply(lambda x: pd.Series(Textblob(x)))\n",
    "\n",
    "    final_data = my_data.drop(columns=['Cleaned_Doc','POS_tagged','Lemma'])\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example - 1 : Use AFINN and TextBlob methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOCUMENT_INDEX</th>\n",
       "      <th>DOCUMENT</th>\n",
       "      <th>TRUE_SENTIMENT</th>\n",
       "      <th>AFINN_Score</th>\n",
       "      <th>TextBlob_polarity</th>\n",
       "      <th>TextBlob_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3360</td>\n",
       "      <td>In 2006  Benjamin Koellmann bought a condomini...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3361</td>\n",
       "      <td>Lugo  a former Catholic bishop who assumed off...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3362</td>\n",
       "      <td>Spanish Wimbledon winner Rafael Nadal said Sun...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3363</td>\n",
       "      <td>In a letter posted on the White House web site...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3364</td>\n",
       "      <td>TAMPA  At least Raheem Morris finally has the ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>3933</td>\n",
       "      <td>In the space of four days   Harvey Weinstein  ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.147917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>3934</td>\n",
       "      <td>Weâll get to the merits of the charges and c...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.276190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>3935</td>\n",
       "      <td>Russia âs president Vladimir Putin  wanted t...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>3936</td>\n",
       "      <td>All five living former US presidents are teami...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.068182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>3937</td>\n",
       "      <td>They call  him  âthe Energizer Bunny.â</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>578 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DOCUMENT_INDEX                                           DOCUMENT   \n",
       "0              3360  In 2006  Benjamin Koellmann bought a condomini...  \\\n",
       "1              3361  Lugo  a former Catholic bishop who assumed off...   \n",
       "2              3362  Spanish Wimbledon winner Rafael Nadal said Sun...   \n",
       "3              3363  In a letter posted on the White House web site...   \n",
       "4              3364  TAMPA  At least Raheem Morris finally has the ...   \n",
       "..              ...                                                ...   \n",
       "573            3933  In the space of four days   Harvey Weinstein  ...   \n",
       "574            3934  Weâll get to the merits of the charges and c...   \n",
       "575            3935  Russia âs president Vladimir Putin  wanted t...   \n",
       "576            3936  All five living former US presidents are teami...   \n",
       "577            3937         They call  him  âthe Energizer Bunny.â   \n",
       "\n",
       "    TRUE_SENTIMENT  AFINN_Score TextBlob_polarity  TextBlob_Score  \n",
       "0          Neutral          0.0          Positive        0.100000  \n",
       "1         Positive          0.0          Positive        0.012500  \n",
       "2         Positive          7.0          Positive        0.250000  \n",
       "3         Positive          0.0          Positive        0.033333  \n",
       "4         Positive          0.0          Negative       -0.100000  \n",
       "..             ...          ...               ...             ...  \n",
       "573        Neutral         -9.0          Positive        0.147917  \n",
       "574       Negative          0.0          Positive        0.276190  \n",
       "575       Negative          8.0           Neutral        0.000000  \n",
       "576       Negative          2.0          Positive        0.068182  \n",
       "577       Positive          0.0           Neutral        0.000000  \n",
       "\n",
       "[578 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentiment_Analysis_lex(r'D:\\lexicon_example.csv','DOCUMENT',['AFINN','TextBlob'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example - 2 : Use All of methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOCUMENT_INDEX</th>\n",
       "      <th>DOCUMENT</th>\n",
       "      <th>TRUE_SENTIMENT</th>\n",
       "      <th>AFINN_Score</th>\n",
       "      <th>SentiWordNet_polarity</th>\n",
       "      <th>SentiWordNet_Score</th>\n",
       "      <th>Vader_polarity</th>\n",
       "      <th>vader_Score</th>\n",
       "      <th>TextBlob_polarity</th>\n",
       "      <th>TextBlob_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3360</td>\n",
       "      <td>In 2006  Benjamin Koellmann bought a condomini...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.125</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.896</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3361</td>\n",
       "      <td>Lugo  a former Catholic bishop who assumed off...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.875</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.913</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3362</td>\n",
       "      <td>Spanish Wimbledon winner Rafael Nadal said Sun...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.500</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.348</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3363</td>\n",
       "      <td>In a letter posted on the White House web site...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.500</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.299</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3364</td>\n",
       "      <td>TAMPA  At least Raheem Morris finally has the ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.125</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>3933</td>\n",
       "      <td>In the space of four days   Harvey Weinstein  ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.875</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.273</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.147917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>3934</td>\n",
       "      <td>Weâll get to the merits of the charges and c...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2.000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.322</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.276190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>3935</td>\n",
       "      <td>Russia âs president Vladimir Putin  wanted t...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.376</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>3936</td>\n",
       "      <td>All five living former US presidents are teami...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.625</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.819</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.068182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>3937</td>\n",
       "      <td>They call  him  âthe Energizer Bunny.â</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.375</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.392</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>578 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DOCUMENT_INDEX                                           DOCUMENT   \n",
       "0              3360  In 2006  Benjamin Koellmann bought a condomini...  \\\n",
       "1              3361  Lugo  a former Catholic bishop who assumed off...   \n",
       "2              3362  Spanish Wimbledon winner Rafael Nadal said Sun...   \n",
       "3              3363  In a letter posted on the White House web site...   \n",
       "4              3364  TAMPA  At least Raheem Morris finally has the ...   \n",
       "..              ...                                                ...   \n",
       "573            3933  In the space of four days   Harvey Weinstein  ...   \n",
       "574            3934  Weâll get to the merits of the charges and c...   \n",
       "575            3935  Russia âs president Vladimir Putin  wanted t...   \n",
       "576            3936  All five living former US presidents are teami...   \n",
       "577            3937         They call  him  âthe Energizer Bunny.â   \n",
       "\n",
       "    TRUE_SENTIMENT  AFINN_Score SentiWordNet_polarity  SentiWordNet_Score   \n",
       "0          Neutral          0.0              Positive               0.125  \\\n",
       "1         Positive          0.0              Negative              -0.875   \n",
       "2         Positive          7.0              Positive               0.500   \n",
       "3         Positive          0.0              Positive               1.500   \n",
       "4         Positive          0.0              Positive               0.125   \n",
       "..             ...          ...                   ...                 ...   \n",
       "573        Neutral         -9.0              Negative              -0.875   \n",
       "574       Negative          0.0              Positive               2.000   \n",
       "575       Negative          8.0              Negative              -0.125   \n",
       "576       Negative          2.0              Positive               0.625   \n",
       "577       Positive          0.0              Positive               0.375   \n",
       "\n",
       "    Vader_polarity  vader_Score TextBlob_polarity  TextBlob_Score  \n",
       "0          Neutral        0.896          Positive        0.100000  \n",
       "1          Neutral        0.913          Positive        0.012500  \n",
       "2         Positive        0.348          Positive        0.250000  \n",
       "3         Positive        0.299          Positive        0.033333  \n",
       "4          Neutral        1.000          Negative       -0.100000  \n",
       "..             ...          ...               ...             ...  \n",
       "573       Negative        0.273          Positive        0.147917  \n",
       "574       Positive        0.322          Positive        0.276190  \n",
       "575       Positive        0.376           Neutral        0.000000  \n",
       "576        Neutral        0.819          Positive        0.068182  \n",
       "577        Neutral        0.392           Neutral        0.000000  \n",
       "\n",
       "[578 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentiment_Analysis_lex(r'D:\\lexicon_example.csv','DOCUMENT','all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
